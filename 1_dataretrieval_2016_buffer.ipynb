{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lbhPzzPuSAId"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports & Setup"
      ],
      "metadata": {
        "id": "no2RxaM5LOCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import ee\n",
        "import geemap\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "from google.colab import drive\n",
        "from datetime import datetime, timedelta\n",
        "import concurrent.futures"
      ],
      "metadata": {
        "id": "zGH5fTC98Jb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT9gC5uF7hw0"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# authenticate & init GEE\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='')"
      ],
      "metadata": {
        "id": "IiJDt2nm_98P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieve filtered data and extraction filters"
      ],
      "metadata": {
        "id": "7dT2Tro8Jc8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read in data created in 1_dataretrieval_2016, since it's already filtered by date\n",
        "df = pd.read_csv(\"/content/drive/2016_LA_merged_scaled.csv\", delimiter=\",\")\n",
        "df.rename(columns={'latitude_x': 'latitude', 'longitude_x':'longitude'}, inplace=True)"
      ],
      "metadata": {
        "id": "Evoj0J8jD-Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bounding_box(df):\n",
        "  '''\n",
        "  create bounding box based on available weather stations\n",
        "  '''\n",
        "  mean_lon, mean_lat = df.longitude.mean(), df.latitude.mean()\n",
        "  min_lon, min_lat = df[['longitude', 'latitude']].values.min(axis=0)\n",
        "  max_lon, max_lat = df[['longitude', 'latitude']].values.max(axis=0)\n",
        "  bounding_box = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])\n",
        "  print('min lon,lat:', min_lon, min_lat)\n",
        "  print('max lon, lat:', max_lon, max_lat)\n",
        "  return bounding_box\n",
        "\n",
        "\n",
        "def get_landsat_tiles(landsat_path, bounding_box, start_date, end_date, overlap):\n",
        "  '''\n",
        "  fetch tiles from path via GEE and filter based on overlap with bounding box\n",
        "  '''\n",
        "  landsat = (ee.ImageCollection(landsat_path).filterBounds(bounding_box).filterDate(start_date, end_date))\n",
        "  bounding_box_area = bounding_box.area()\n",
        "\n",
        "  def compute_overlap(image):\n",
        "      overlap = image.geometry().intersection(bounding_box).area().divide(bounding_box_area)\n",
        "      return image.set('overlap_fraction', overlap)\n",
        "\n",
        "  landsat_filt = landsat.map(compute_overlap).filter(ee.Filter.gte('overlap_fraction', overlap))\n",
        "  print('number of days:', landsat_filt.size().getInfo())\n",
        "  return landsat, landsat_filt\n",
        "\n",
        "\n",
        "def get_avail_landsat_dates(landsat_filt):\n",
        "  '''\n",
        "  get dates at which landsat images are available (use correct timezone!!)\n",
        "  '''\n",
        "  avail_dates = landsat_filt.aggregate_array('system:time_start').map(\n",
        "      lambda d: ee.Date(d).format('YYYY-MM-dd HH:mm:ss', 'America/Los_Angeles')\n",
        "  ).distinct().getInfo()\n",
        "  return avail_dates"
      ],
      "metadata": {
        "id": "Aii6FC9QE4xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = '2016-01-01'\n",
        "end_date = '2016-12-31'"
      ],
      "metadata": {
        "id": "yrrMg2Ommpde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bounding_box = get_bounding_box(df)\n",
        "landsat, landsat_filt = get_landsat_tiles(\"LANDSAT/LC08/C02/T1_L2\", bounding_box, start_date, end_date, 0.7)\n",
        "avail_dates = get_avail_landsat_dates(landsat_filt)\n",
        "print(avail_dates)"
      ],
      "metadata": {
        "id": "YD9zrbl_FC-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extract data and compute statistics from buffered data"
      ],
      "metadata": {
        "id": "djp170UgLaH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bands(landsat):\n",
        "  '''\n",
        "  extract, preprocess, and scale landsat bands\n",
        "  '''\n",
        "  # Develop masks for unwanted pixels (fill, cloud, cloud shadow).\n",
        "  qa_mask = landsat.select('QA_PIXEL').bitwiseAnd(0b11111).eq(0)\n",
        "  saturation_mask = landsat.select('QA_RADSAT').eq(0)\n",
        "\n",
        "  # Apply the scaling factors to the appropriate bands.\n",
        "  def _get_factor_img(factor_names):\n",
        "      factor_list = landsat.toDictionary().select(factor_names).values()\n",
        "      return ee.Image.constant(factor_list)\n",
        "\n",
        "  scale_img = _get_factor_img([\n",
        "      'REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10'])\n",
        "  offset_img = _get_factor_img([\n",
        "      'REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10'])\n",
        "  scaled = landsat.select('SR_B.|ST_B10').multiply(scale_img).add(offset_img)\n",
        "\n",
        "  landsat = landsat.addBands(scaled, None, True).updateMask(\n",
        "      qa_mask).updateMask(saturation_mask)\n",
        "\n",
        "  red = landsat.select('SR_B4').rename('Red')\n",
        "  green = landsat.select('SR_B3').rename('Green')\n",
        "  blue = landsat.select('SR_B2').rename('Blue')\n",
        "  swir1 = landsat.select('SR_B6').rename('SWIR1')\n",
        "  swir2 = landsat.select('SR_B7').rename('SWIR2')\n",
        "  lst = landsat.select('ST_B10').rename('LST').subtract(273.15)\n",
        "\n",
        "  # compute indices\n",
        "  ndvi = landsat.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')\n",
        "  ndbi = landsat.normalizedDifference(['SR_B6', 'SR_B5']).rename('NDBI')\n",
        "  nbai = landsat.normalizedDifference(['SR_B7', 'SR_B5']).rename('NBAI')\n",
        "  mndwi = landsat.normalizedDifference(['SR_B3', 'SR_B6']).rename('MNDWI')\n",
        "\n",
        "  band_dict = {\n",
        "      'NIR': landsat.select('SR_B5'),\n",
        "      'RED': landsat.select('SR_B4'),\n",
        "      'BLUE': landsat.select('SR_B2')\n",
        "  }\n",
        "\n",
        "  evi = landsat.expression('2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', band_dict).rename('EVI')\n",
        "  savi = landsat.expression('((NIR - RED) / (NIR + RED + 0.5)) * 1.5', band_dict).rename('SAVI')\n",
        "\n",
        "  return lst.addBands([red, green, blue, swir1, swir2, ndvi, evi, savi, mndwi, nbai, ndbi])\n",
        "\n",
        "\n",
        "\n",
        "def compute_buffer_stats(feature, bands_date):\n",
        "  '''\n",
        "  compute mean and standard deviation of each band for each buffer size\n",
        "  '''\n",
        "  point = ee.Geometry(feature['geometry'])\n",
        "  buffered_geometries = {size: point.buffer(size) for size in buffer_sizes}\n",
        "  stats = {}\n",
        "\n",
        "  reduction = bands_date.reduceRegion(\n",
        "      reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), sharedInputs=True),\n",
        "      geometry=ee.Geometry.MultiPolygon(list(buffered_geometries.values())),\n",
        "      scale=30,\n",
        "      bestEffort=True,\n",
        "      maxPixels=1e13\n",
        "  ).getInfo()\n",
        "\n",
        "  for buffer_size, geom in buffered_geometries.items():\n",
        "      for key, value in reduction.items():\n",
        "          stats[f\"{key}_{buffer_size}m\"] = value\n",
        "\n",
        "  return stats\n",
        "\n",
        "\n",
        "def sample_bands_via_target_location(landsat_filt, df):\n",
        "  '''\n",
        "  for the given available date, extract landsat bands and terrain images, and sample buffer data given target locations\n",
        "  '''\n",
        "  total_arr = []\n",
        "  for i in range(landsat_filt.size().getInfo()):\n",
        "      image = ee.Image(landsat_filt.toList(1, i).get(0))\n",
        "      datet = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
        "      print(datet)\n",
        "\n",
        "      features = []\n",
        "      # for _, row in df[df.date == datetime.strptime(datet, '%Y-%m-%d').date()].iterrows(): # if df.date is datetime\n",
        "      for _, row in df[df.date == datet].iterrows(): # if df.date is string\n",
        "\n",
        "          point = ee.Geometry.Point([row['longitude'], row['latitude']])\n",
        "          feature = ee.Feature(point, {\"temperature\": row[\"temperature\"], \"sid\": row[\"sid\"], \"date\": str(row[\"date\"])})\n",
        "          features.append(feature)\n",
        "\n",
        "      fc_date = ee.FeatureCollection(features)\n",
        "      bands_date = extract_bands(image)\n",
        "\n",
        "      # extra non-temporally dependent\n",
        "      srtm = ee.Image(\"USGS/SRTMGL1_003\").select(\"elevation\").rename(\"Elevation\")\n",
        "      elevation = srtm.clip(bounding_box)\n",
        "      slope = ee.Terrain.slope(srtm).rename(\"Slope\")\n",
        "      slope = slope.clip(bounding_box)\n",
        "      # distance to water using ESA WorldCover (water mask = 80)\n",
        "      water = ee.Image(\"ESA/WorldCover/v200/2021\").select(\"Map\").eq(80).selfMask()\n",
        "      water_dist = water.fastDistanceTransform().rename(\"Water_dist\")\n",
        "\n",
        "      bands_date = bands_date.addBands([elevation, slope, water_dist])\n",
        "\n",
        "      # parallelise for SPEEEED\n",
        "      with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "          futures = []\n",
        "          for fcd_feature in fc_date.getInfo()['features']:\n",
        "              props = fcd_feature['properties']\n",
        "              sid = props['sid']\n",
        "              date = props['date']\n",
        "\n",
        "              future = executor.submit(compute_buffer_stats, fcd_feature, bands_date)\n",
        "              futures.append((future, sid, date))\n",
        "\n",
        "          for future, sid, date in futures:\n",
        "              stats = future.result()\n",
        "              total_arr.append({'sid': sid, 'date': date, **stats})\n",
        "              print('.', end='', flush=True)\n",
        "\n",
        "  return total_arr"
      ],
      "metadata": {
        "id": "79186El9F4qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "buffer_sizes = [ 30, 100, 200, 500, 1000]\n",
        "data_list = sample_bands_via_target_location(landsat_filt, df)\n",
        "buffer_df = pd.DataFrame(data_list)"
      ],
      "metadata": {
        "id": "6kYZlELdHf0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Merge with target data"
      ],
      "metadata": {
        "id": "-LioQelBLiKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge extracted buffer-computed features with target data\n",
        "df_la_2016_buffer = pd.merge(df, buffer_df, on=['sid', 'date'], how='left').dropna()\n",
        "df_la_2016_buffer"
      ],
      "metadata": {
        "id": "lgpjjZO20-MI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_numeric = df_la_2016_buffer[list(df_la_2016_buffer.columns[31:])+['temperature']]\n",
        "corr_matrix = df_numeric.select_dtypes(include='number').corr()\n",
        "\n",
        "# variables where correlation is bigger than 0.1\n",
        "corr_high = pd.DataFrame(corr_matrix[abs(corr_matrix) > 0.14]['temperature'].dropna().sort_values(ascending=False))\n",
        "display(corr_high)"
      ],
      "metadata": {
        "id": "uRBB6onjOCGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save to file\n",
        "df_la_2016_buffer.to_csv('/content/drive/2016_LA_merged_scaled_buffer.csv', index=False)"
      ],
      "metadata": {
        "id": "TH7jilNm0_uq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}