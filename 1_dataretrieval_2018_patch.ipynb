{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports & Setup"
      ],
      "metadata": {
        "id": "u9lL5kGYMMTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import ee\n",
        "import geemap\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "from google.colab import drive\n",
        "from datetime import datetime, timedelta\n",
        "import concurrent.futures\n",
        "import torch\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "zGH5fTC98Jb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT9gC5uF7hw0"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# authenticate & init GEE\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='')"
      ],
      "metadata": {
        "id": "IiJDt2nm_98P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieved filtered year data"
      ],
      "metadata": {
        "id": "BPHIRgL6RReP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/2018_LA_merged_scaled.csv\", delimiter=\",\")\n",
        "df.rename(columns={'latitude_x': 'latitude', 'longitude_x':'longitude'}, inplace=True)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Evoj0J8jD-Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bounding_box(df):\n",
        "  '''\n",
        "  create bounding box based on available weather stations\n",
        "  '''\n",
        "  mean_lon, mean_lat = df.longitude.mean(), df.latitude.mean()\n",
        "  min_lon, min_lat = df[['longitude', 'latitude']].values.min(axis=0)\n",
        "  max_lon, max_lat = df[['longitude', 'latitude']].values.max(axis=0)\n",
        "  bounding_box = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])\n",
        "  print('min lon,lat:', min_lon, min_lat)\n",
        "  print('max lon, lat:', max_lon, max_lat)\n",
        "  return bounding_box\n",
        "\n",
        "\n",
        "def get_landsat_tiles(landsat_path, bounding_box, start_date, end_date, overlap):\n",
        "  '''\n",
        "  fetch tiles from path via GEE and filter based on overlap with bounding box\n",
        "  '''\n",
        "  landsat = (ee.ImageCollection(landsat_path).filterBounds(bounding_box).filterDate(start_date, end_date))\n",
        "  bounding_box_area = bounding_box.area()\n",
        "\n",
        "  def compute_overlap(image):\n",
        "      overlap = image.geometry().intersection(bounding_box).area().divide(bounding_box_area)\n",
        "      return image.set('overlap_fraction', overlap)\n",
        "\n",
        "  landsat_filt = landsat.map(compute_overlap).filter(ee.Filter.gte('overlap_fraction', overlap))\n",
        "  print('number of days:', landsat_filt.size().getInfo())\n",
        "  return landsat, landsat_filt\n",
        "\n",
        "\n",
        "def get_avail_landsat_dates(landsat_filt):\n",
        "  '''\n",
        "  get dates at which landsat images are available (use correct timezone!!)\n",
        "  '''\n",
        "  avail_dates = landsat_filt.aggregate_array('system:time_start').map(\n",
        "      lambda d: ee.Date(d).format('YYYY-MM-dd HH:mm:ss', 'America/Los_Angeles')\n",
        "  ).distinct().getInfo()\n",
        "  return avail_dates"
      ],
      "metadata": {
        "id": "Aii6FC9QE4xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = '2018-01-01'\n",
        "end_date = '2018-12-31'"
      ],
      "metadata": {
        "id": "yrrMg2Ommpde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Patch Extraction"
      ],
      "metadata": {
        "id": "QJj-DrRUupwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bounding_box = get_bounding_box(df)\n",
        "landsat, landsat_filt = get_landsat_tiles(\"LANDSAT/LC08/C02/T1_L2\", bounding_box, start_date, end_date, 0.7)\n",
        "avail_dates = get_avail_landsat_dates(landsat_filt)\n",
        "print(avail_dates)"
      ],
      "metadata": {
        "id": "YD9zrbl_FC-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_bands(landsat):\n",
        "  '''\n",
        "  extract, preprocess, and scale landsat bands\n",
        "  '''\n",
        "  # Develop masks for unwanted pixels (fill, cloud, cloud shadow).\n",
        "  qa_mask = landsat.select('QA_PIXEL').bitwiseAnd(0b11111).eq(0)\n",
        "  saturation_mask = landsat.select('QA_RADSAT').eq(0)\n",
        "\n",
        "  # Apply the scaling factors to the appropriate bands.\n",
        "  def _get_factor_img(factor_names):\n",
        "      factor_list = landsat.toDictionary().select(factor_names).values()\n",
        "      return ee.Image.constant(factor_list)\n",
        "\n",
        "  scale_img = _get_factor_img([\n",
        "      'REFLECTANCE_MULT_BAND_.|TEMPERATURE_MULT_BAND_ST_B10'])\n",
        "  offset_img = _get_factor_img([\n",
        "      'REFLECTANCE_ADD_BAND_.|TEMPERATURE_ADD_BAND_ST_B10'])\n",
        "  scaled = landsat.select('SR_B.|ST_B10').multiply(scale_img).add(offset_img)\n",
        "\n",
        "  landsat = landsat.addBands(scaled, None, True).updateMask(\n",
        "      qa_mask).updateMask(saturation_mask)\n",
        "\n",
        "  red = landsat.select('SR_B4').rename('Red')\n",
        "  green = landsat.select('SR_B3').rename('Green')\n",
        "  blue = landsat.select('SR_B2').rename('Blue')\n",
        "  swir1 = landsat.select('SR_B6').rename('SWIR1')\n",
        "  swir2 = landsat.select('SR_B7').rename('SWIR2')\n",
        "  lst = landsat.select('ST_B10').rename('LST').subtract(273.15)\n",
        "\n",
        "  # compute indices\n",
        "  ndvi = landsat.normalizedDifference(['SR_B5', 'SR_B4']).rename('NDVI')\n",
        "  ndbi = landsat.normalizedDifference(['SR_B6', 'SR_B5']).rename('NDBI')\n",
        "  nbai = landsat.normalizedDifference(['SR_B7', 'SR_B5']).rename('NBAI')\n",
        "  mndwi = landsat.normalizedDifference(['SR_B3', 'SR_B6']).rename('MNDWI')\n",
        "\n",
        "  band_dict = {\n",
        "      'NIR': landsat.select('SR_B5'),\n",
        "      'RED': landsat.select('SR_B4'),\n",
        "      'BLUE': landsat.select('SR_B2')\n",
        "  }\n",
        "\n",
        "  evi = landsat.expression('2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', band_dict).rename('EVI')\n",
        "  savi = landsat.expression('((NIR - RED) / (NIR + RED + 0.5)) * 1.5', band_dict).rename('SAVI')\n",
        "\n",
        "  return lst.addBands([red, green, blue, swir1, swir2, ndvi, evi, savi, mndwi, nbai, ndbi])"
      ],
      "metadata": {
        "id": "79186El9F4qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_patch(fcd_feature, bands_date, patch_size):\n",
        "  '''\n",
        "  extract an image patch/sample a rectangle at the given target location,\n",
        "  ensure all aptch sizes are the same\n",
        "  '''\n",
        "  patch_square = ee.Geometry.Point(fcd_feature['geometry']['coordinates']).buffer(patch_size/2 * 31).bounds() # extra 1 to ensure bigger & clip instead of clip\n",
        "  patch = bands_date.sampleRectangle(region=patch_square, defaultValue=0, defaultArrayValue=0)\n",
        "  patch_data = patch.getInfo()\n",
        "\n",
        "  patch_image = []\n",
        "  for i, band in enumerate(patch_data['properties']):\n",
        "      band_patch = np.array(patch_data['properties'][band])\n",
        "\n",
        "      # sometimes incorrectly sized, crop all to 64x64\n",
        "      height, width = band_patch.shape\n",
        "      if height > patch_size or width > patch_size:\n",
        "          start_x = (width - patch_size) // 2 if width > patch_size else 0\n",
        "          start_y = (height - patch_size) // 2 if height > patch_size else 0\n",
        "          band_patch = band_patch[start_y:start_y + patch_size, start_x:start_x + patch_size]\n",
        "      if height < patch_size or width < patch_size:\n",
        "          band_patch = np.pad(band_patch, ((max(0, (patch_size - height) // 2), max(0, (patch_size - height) // 2)),\n",
        "            (max(0, (patch_size - width) // 2), max(0, (patch_size - width) // 2))),mode='constant', constant_values=0)\n",
        "\n",
        "      patch_image.append(band_patch)\n",
        "\n",
        "  patch_image = np.stack(patch_image, axis=-1)\n",
        "  patch_image = patch_image / 10000\n",
        "\n",
        "  return patch_image"
      ],
      "metadata": {
        "id": "Rufxr4Nl0COb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_bands_via_target_location_as_patches(landsat_filt, df, patch_size):\n",
        "  '''\n",
        "  for the given available date, extract landsat bands and terrain images, and sample patches given target locations\n",
        "  '''\n",
        "  arr_temp = []\n",
        "  arr_date = []\n",
        "  arr_image = []\n",
        "\n",
        "  for i in range(landsat_filt.size().getInfo()):\n",
        "      image = ee.Image(landsat_filt.toList(1, i).get(0))\n",
        "      datet = ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()\n",
        "      print(datet)\n",
        "\n",
        "      features = []\n",
        "      # for _, row in df[df.date == datetime.strptime(datet, '%Y-%m-%d').date()].iterrows(): # if df.date is datetime\n",
        "      for _, row in df[df.date == datet].iterrows(): # if df.date is string\n",
        "          point = ee.Geometry.Point([row['longitude'], row['latitude']])\n",
        "          feature = ee.Feature(point, {\n",
        "              \"temperature\": row[\"temperature\"],\n",
        "              \"sid\": row[\"sid\"],\n",
        "              \"date\": str(row[\"date\"])\n",
        "          })\n",
        "          features.append(feature)\n",
        "\n",
        "      fc_date = ee.FeatureCollection(features)\n",
        "      bands_date = extract_bands(image)\n",
        "\n",
        "      # extra non-temporally dependent\n",
        "      srtm = ee.Image(\"USGS/SRTMGL1_003\").select(\"elevation\").rename(\"Elevation\")\n",
        "      elevation = srtm.clip(bounding_box)\n",
        "      slope = ee.Terrain.slope(srtm).rename(\"Slope\")\n",
        "      slope = slope.clip(bounding_box)\n",
        "      # distance to water using ESA WorldCover (water mask = 80), resample to 30m res\n",
        "      water = ee.Image(\"ESA/WorldCover/v200/2021\").select(\"Map\").eq(80).selfMask()\n",
        "      water_dist = water.fastDistanceTransform().rename(\"Water_dist\")\n",
        "      water_dist = water_dist.reduceResolution(reducer=ee.Reducer.mean(), bestEffort=True).reproject(crs=bands_date.projection(), scale=30)\n",
        "\n",
        "      bands_date = bands_date.addBands([elevation, slope, water_dist])\n",
        "\n",
        "      # parallelise\n",
        "      with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        # sample patch at each feature\n",
        "\n",
        "        for fcd_feature in fc_date.getInfo()['features']:\n",
        "            future = executor.submit(extract_patch, fcd_feature, bands_date, patch_size)\n",
        "            futures.append(future)\n",
        "\n",
        "            # encode date\n",
        "            props = fcd_feature['properties']\n",
        "            sid = props['sid']\n",
        "            date = props['date']\n",
        "            temperature = props['temperature']\n",
        "\n",
        "            dayofyear = datetime.strptime(date, '%Y-%m-%d').timetuple().tm_yday\n",
        "            sintime = np.sin(2 * np.pi * dayofyear / 365)\n",
        "            costime = np.cos(2 * np.pi * dayofyear / 365)\n",
        "\n",
        "            arr_temp.append(temperature)\n",
        "            arr_date.append([sintime, costime])\n",
        "\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            print('.', end='', flush=True)\n",
        "            patch_image = future.result()\n",
        "            arr_image.append(patch_image)\n",
        "\n",
        "  X_image = torch.tensor(np.array(arr_image), dtype=torch.float32)\n",
        "  # date array implementaiton is actually wrong, but is fixed in the notebook applying the actual data\n",
        "  X_date = torch.tensor(np.array(arr_date), dtype=torch.float32)\n",
        "  Y_temp = torch.tensor(np.array(arr_temp), dtype=torch.float32)\n",
        "\n",
        "  return X_image, date, Y_temp"
      ],
      "metadata": {
        "id": "HTWVH480p5Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch_size = 64\n",
        "X_image, X_date, Y_temp = sample_bands_via_target_location_as_patches(landsat_filt, df, patch_size)"
      ],
      "metadata": {
        "id": "0y-C1zZQp6Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Size & visualisation checks"
      ],
      "metadata": {
        "id": "9majeXi9Ra2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_image.shape)\n",
        "print(Y_temp.shape)"
      ],
      "metadata": {
        "id": "ynk7P7vjjiTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to plot a one \"row\", i.e. all bands (no ittles)\n",
        "patch_bands = X_image[28]\n",
        "fig, axs = plt.subplots(3, 5, figsize=(15, 8))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i in range(15):\n",
        "  axs[i].imshow(patch_bands[:,:,i])\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ef6At0_7kvMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(X_image, '/content/drive/64/X_image_2018_64.pt')\n",
        "# torch.save(X_date, '/content/drive/64/X_date_2017_64.pt') # wrong hihi\n",
        "torch.save(Y_temp, '/content/drive/64/Y_temp_2018_64.pt')"
      ],
      "metadata": {
        "id": "S2rhzNRxpOm2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}